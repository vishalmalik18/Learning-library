import numpy as np
import matplotlib.pylot as plt

%matplotlib inline
def gradient_descent(x,y):
  m_curr = b_curr =0
  iterations = 0.01
  n = len(x)
  learning_rate(x)

  plt.scatter(x,y,color='red',marker='+',linewidth='5')
  for i in range(iterations):
     yp = m_curr * x + b_curr
     cost = (1/n) * sum([val**2 for val in (y-yp)])
     md = -(2/n) * sum(x*(y-yp))
     bd = -(2/n) * sum(y-yp))
     m_curr = m_curr - learing_rate * md
     b_curr = b_curr - learing_rate * md
     print("m {},b{},cost{},iteration{}".format(m_curr,b_curr,cost,i))


x = np.array([1,2,3,4,5])
y = np.array([5,7,9,11,13])

gradient_descent(x,y)